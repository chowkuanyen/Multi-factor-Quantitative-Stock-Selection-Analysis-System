import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
from typing import Callable, Dict, Any, List
import pandas_ta as ta
import numpy as np
import xlsxwriter

# 忽略 pandas 的 SettingWithCopyWarning
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)


# ==============================================================================
# 核心工具函数和配置
# ==============================================================================
class Config:
    """程序配置类"""

    def __init__(self):
        self.HOME_DIRECTORY = os.path.expanduser('~')
        self.SAVE_DIRECTORY = os.path.join(self.HOME_DIRECTORY, 'Downloads', 'CoreNews_Reports')
        self.TEMP_DATA_DIRECTORY = os.path.join(self.SAVE_DIRECTORY, 'ShareData')
        self.DATA_FETCH_RETRIES = 3
        self.DATA_FETCH_DELAY = 5
        self.MAX_WORKERS = 15
        self.CODE_ALIASES = {'代码': '股票代码', '证券代码': '股票代码', '股票代码': '股票代码'}
        # 别名已包含所有常见名称
        self.NAME_ALIASES = {'名称': '股票简称', '股票名称': '股票简称', '股票简称': '股票简称', '简称': '股票简称',
                             '简': '股票简称', '证券名称': '股票简称'}
        # === 价格别名修复 v5：涵盖更多实时行情价格字段 ===
        self.PRICE_ALIASES = {'最新价': '最新价', '现价': '最新价', '收盘价': '最新价',
                              'close': '最新价', '最新价格': '最新价'}
        self.CHANGE_RATE_ALIASES = {'涨跌幅': '涨跌幅', 'change_rate': '涨跌幅', '幅度': '涨跌幅',
                                    '涨幅': '涨跌幅'}
        # === 时间周期常量 ===
        self.TODAY_STR = datetime.now().strftime('%Y-%m-%d')
        self.YESTERDAY_STR = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

        # 确保目录存在
        os.makedirs(self.SAVE_DIRECTORY, exist_ok=True)
        os.makedirs(self.TEMP_DATA_DIRECTORY, exist_ok=True)

        print(f"配置文件已加载。报告将保存至: {self.SAVE_DIRECTORY}")

CFG = Config()


def _standardize_columns(df: pd.DataFrame, code_aliases: Dict[str, str], name_aliases: Dict[str, str],
                         price_aliases: Dict[str, str], change_rate_aliases: Dict[str, str]) -> pd.DataFrame:
    """标准化 DataFrame 的列名，统一为 '股票代码', '股票简称', '最新价', '涨跌幅'"""
    if df.empty:
        return df

    # 定义一个内部函数来查找并替换列名
    def find_and_rename(df: pd.DataFrame, aliases: Dict[str, str]) -> pd.DataFrame:
        """根据别名字典查找并替换列名，忽略大小写和空格"""
        new_names = {}
        target_name = list(aliases.values())[0]

        for col in df.columns:
            # 清理并规范化当前的列名
            normalized_col = col.strip().lower().replace('_', '').replace('-', '')
            # 查找匹配的别名
            for alias, standard_name in aliases.items():
                normalized_alias = alias.strip().lower().replace('_', '').replace('-', '')
                if normalized_col == normalized_alias:
                    # 检查是否已存在标准列名，避免重复重命名
                    if target_name not in df.columns:
                        new_names[col] = standard_name
                    elif col != standard_name:
                        # 如果目标列名已存在，但当前列名不是目标列名，则跳过重命名，避免冲突
                        pass
                    break  # 找到一个匹配项后即可跳出内层循环

        if new_names:
            df = df.rename(columns=new_names)

        # 检查是否包含标准列名，如果标准列名已存在，则不再进行其他别名替换
        if target_name in df.columns:
            return df
        # 否则，返回原始DataFrame，等待下一个别名组处理

        return df

    # 依次处理并替换列名
    df = find_and_rename(df, code_aliases)
    df = find_and_rename(df, name_aliases)
    df = find_and_rename(df, price_aliases)
    df = find_and_rename(df, change_rate_aliases)

    # 最终确保保留需要的列
    required_cols = ['股票代码', '股票简称', '最新价', '涨跌幅']
    final_cols = [col for col in required_cols if col in df.columns]
    
    # 将标准列移到最前面
    existing_cols = [col for col in df.columns if col not in final_cols]
    df = df[final_cols + existing_cols]

    return df


def _fetch_data_with_retry(fetch_func: Callable[[], pd.DataFrame],
                           func_name: str,
                           retries: int = CFG.DATA_FETCH_RETRIES,
                           delay: int = CFG.DATA_FETCH_DELAY) -> pd.DataFrame:
    """带重试机制的数据抓取函数"""
    for i in range(retries):
        try:
            print(f"[{func_name}] 正在尝试抓取数据 (第 {i + 1} 次)...")
            result = fetch_func()
            if result is not None and not result.empty:
                print(f"[{func_name}] 数据抓取成功。")
                return result
            elif result is not None:
                # 即使抓到了空 DataFrame，也视为成功，因为可能是当天无数据
                print(f"[{func_name}] 数据抓取成功，但返回空集。")
                return pd.DataFrame()
        except Exception as e:
            print(f"[ERROR] [{func_name}] 数据抓取失败 (第 {i + 1} 次): {e}")
            if i < retries - 1:
                print(f"[{func_name}] 等待 {delay} 秒后重试...")
                time.sleep(delay)
    print(f"[FATAL] [{func_name}] 数据抓取重试 {retries} 次后仍失败。返回空 DataFrame。")
    return pd.DataFrame()


def _get_trade_day(days: int = 0) -> str:
    """获取指定偏移量的交易日，days=0表示当天，days=-1表示前一个交易日"""
    # 简单实现，只考虑日期的偏移，不严格判断是否为交易日，依赖 AkShare 内部判断
    target_date = datetime.now() + timedelta(days=days)
    return target_date.strftime('%Y%m%d')


def _save_temp_data(df: pd.DataFrame, file_name: str):
    """保存临时数据到本地，用于调试和下次启动加速"""
    if not df.empty:
        try:
            file_path = os.path.join(CFG.TEMP_DATA_DIRECTORY, file_name)
            df.to_parquet(file_path, index=False)
            # print(f"[DEBUG] 临时数据已保存: {file_name}")
        except Exception as e:
            print(f"[WARN] 临时数据保存失败 {file_name}: {e}")


def _load_temp_data(file_name: str) -> pd.DataFrame:
    """从本地加载临时数据"""
    file_path = os.path.join(CFG.TEMP_DATA_DIRECTORY, file_name)
    if os.path.exists(file_path):
        try:
            df = pd.read_parquet(file_path)
            # print(f"[DEBUG] 临时数据已加载: {file_name}")
            return df
        except Exception as e:
            print(f"[WARN] 临时数据加载失败或文件损坏 {file_name}: {e}")
            return pd.DataFrame()
    return pd.DataFrame()


# ==============================================================================
# 数据抓取模块
# ==============================================================================
class DataFetcher:
    """负责所有原始数据的抓取"""

    def __init__(self):
        self.raw_data = {}

    def _fetch_main_report_data(self) -> pd.DataFrame:
        """抓取主力研报数据"""
        # 抓取最近 3 天的研报
        start_date = (datetime.now() - timedelta(days=3)).strftime('%Y%m%d')
        end_date = datetime.now().strftime('%Y%m%d')
        df = ak.stock_research_report_em(start_date=start_date, end_date=end_date)
        return df

    def _fetch_spot_data(self) -> pd.DataFrame:
        """抓取所有A股实时行情数据"""
        df = ak.stock_zh_a_spot_em()
        return df

    def _fetch_market_fund_flow(self) -> pd.DataFrame:
        """抓取市场资金流向排名"""
        df = ak.fund_flow_market_industry(indicator="5日")
        return df

    def _fetch_strong_stocks(self) -> pd.DataFrame:
        """抓取强势股池（5日新高）"""
        df = ak.stock_hot_rank_em(symbol="5日新高")
        return df

    def _fetch_consecutive_rise(self) -> pd.DataFrame:
        """抓取连续上涨个股"""
        df = ak.stock_hot_rank_em(symbol="连续上涨")
        return df

    def _fetch_ljqs_data(self) -> pd.DataFrame:
        """抓取量价齐升个股"""
        df = ak.stock_hot_rank_em(symbol="量价齐升")
        return df

    def _fetch_cxfl_data(self) -> pd.DataFrame:
        """抓取持续放量个股"""
        df = ak.stock_hot_rank_em(symbol="持续放量")
        return df

    def _fetch_top_industry_cons(self) -> pd.DataFrame:
        """抓取前十行业板块的成分股"""
        df = ak.stock_board_industry_name_em()
        if df.empty:
            return pd.DataFrame()

        # 选取前 10 个板块
        top_10_industries = df.head(10)['板块名称'].tolist()
        all_cons_df = []

        def get_industry_cons(industry_name):
            try:
                # 获取板块成分股
                cons_df = ak.stock_board_industry_cons_em(symbol=industry_name)
                if not cons_df.empty:
                    cons_df['板块名称'] = industry_name
                return cons_df
            except Exception as e:
                print(f"[ERROR] 抓取板块成分股失败: {industry_name}: {e}")
                return pd.DataFrame()

        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_industry = {executor.submit(get_industry_cons, ind): ind for ind in top_10_industries}
            for future in as_completed(future_to_industry):
                cons_df = future.result()
                if not cons_df.empty:
                    all_cons_df.append(cons_df)

        if all_cons_df:
            final_df = pd.concat(all_cons_df, ignore_index=True)
            return final_df.drop_duplicates(subset=['股票代码'])  # 移除重复股票
        return pd.DataFrame()

    def _fetch_daily_k_data(self, symbol: str) -> pd.DataFrame:
        """抓取个股近 100 天的 K 线数据，用于技术指标计算"""
        # 注意：这里使用前 100 天的数据是为了确保技术指标计算所需周期足够
        # 实际交易日期范围会由 AkShare 自动处理
        try:
            df = ak.stock_zh_a_hist(symbol=symbol, period="daily", start_date="20240101", adjust="qfq") # 使用 qfq
            if df.empty:
                return pd.DataFrame()
            # 简化列名
            df.columns = ['日期', '开盘', '收盘', '最高', '最低', '成交量', '成交额', '振幅', '涨跌幅', '涨跌额', '换手率']
            df['日期'] = pd.to_datetime(df['日期'])
            return df.tail(100).reset_index(drop=True)
        except Exception as e:
            # print(f"[WARN] 抓取 {symbol} K 线数据失败: {e}")
            return pd.DataFrame()

    def fetch_all_data(self) -> Dict[str, Any]:
        """抓取所有原始数据"""
        start_time = time.time()
        print("\n--- 1. 开始抓取原始数据 ---")

        # 定义需要并发抓取的数据源
        tasks = {
            'main_report_raw': self._fetch_main_report_data,
            'spot_data_raw': self._fetch_spot_data,
            'market_fund_flow_raw': self._fetch_market_fund_flow,
            'strong_stocks_raw': self._fetch_strong_stocks,
            'consecutive_rise_raw': self._fetch_consecutive_rise,
            'ljqs_raw': self._fetch_ljqs_data,
            'cxfl_raw': self._fetch_cxfl_data,
            'top_industry_cons_df': self._fetch_top_industry_cons, # 独立抓取
        }

        # 使用多线程抓取数据
        with ThreadPoolExecutor(max_workers=CFG.MAX_WORKERS) as executor:
            future_to_task = {executor.submit(_fetch_data_with_retry, func, name): name for name, func in tasks.items()}
            for future in as_completed(future_to_task):
                name = future_to_task[future]
                try:
                    self.raw_data[name] = future.result()
                except Exception as exc:
                    print(f"[{name}] 生成了一个异常: {exc}")
                    self.raw_data[name] = pd.DataFrame()

        end_time = time.time()
        print(f"--- 1. 原始数据抓取完成，耗时: {end_time - start_time:.2f} 秒 ---")
        return self.raw_data


# ==============================================================================
# 数据处理模块
# ==============================================================================
class DataProcessor:
    """负责原始数据的清洗、转换和指标计算"""

    def __init__(self, raw_data: Dict[str, Any]):
        self.raw_data = raw_data
        self.processed_data = {}

    def _clean_and_standardize_data(self) -> None:
        """清洗并标准化所有 DataFrame"""
        print("\n--- 2.1. 开始清洗和标准化数据 ---")
        for key, df in self.raw_data.items():
            if isinstance(df, pd.DataFrame) and not df.empty:
                # 只对包含股票代码的数据进行标准化处理
                if 'spot_data_raw' in key or 'report' in key or 'stocks' in key or 'rise' in key or 'ljqs' in key or 'cxfl' in key or 'cons' in key:
                    df = _standardize_columns(df.copy(), CFG.CODE_ALIASES, CFG.NAME_ALIASES, CFG.PRICE_ALIASES, CFG.CHANGE_RATE_ALIASES)
                
                # 统一股票代码格式：上海 A 股以 6 开头，深圳 A 股以 0 或 3 开头，全部转为字符串
                if '股票代码' in df.columns:
                    # 确保是字符串
                    df['股票代码'] = df['股票代码'].astype(str).str.zfill(6)
                    # 移除不是 A 股的代码（例如：B股、基金等，简单通过代码开头过滤）
                    df = df[df['股票代码'].str.startswith(('6', '0', '3'))].copy()
                
                # 清洗价格和涨跌幅，确保为数值类型
                for col in ['最新价', '涨跌幅']:
                    if col in df.columns:
                        # 尝试将非数值转换为 NaN
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # 移除所有含有 NaN 的行
                df = df.dropna(subset=['股票代码'])


            self.processed_data[f"processed_{key.replace('_raw', '').replace('_df', '')}"] = df
            
        print("--- 2.1. 数据清洗和标准化完成 ---")

    def _process_main_report(self) -> pd.DataFrame:
        """处理主力研报，进行关键词筛选和去重"""
        df = self.processed_data.get('processed_main_report', pd.DataFrame())
        if df.empty:
            return df

        # 筛选关键词：'买入', '增持', '推荐', '强烈推荐', '跑赢行业', '首次覆盖'
        keywords = ['买入', '增持', '推荐', '强烈推荐', '跑赢行业', '首次覆盖']
        df_filtered = df[df['评级'].str.contains('|'.join(keywords), na=False)].copy()

        # 转换为日期类型，以便后续排序和去重
        df_filtered['日期'] = pd.to_datetime(df_filtered['日期'])
        df_filtered['股票代码'] = df_filtered['股票代码'].astype(str)

        # 按 '股票代码', '券商', '评级' 和 '日期' 降序排序
        df_sorted = df_filtered.sort_values(by=['股票代码', '券商', '评级', '日期'], ascending=[True, True, True, False])

        # 保留每个 '股票代码' 和 '券商' 组合下的最新一条研报
        df_dedup = df_sorted.drop_duplicates(subset=['股票代码', '券商'], keep='first')

        # 只保留所需列
        required_cols = ['日期', '股票代码', '股票简称', '标题', '券商', '评级']
        return df_dedup[required_cols]

    def _process_xstp_signal(self) -> pd.DataFrame:
        """处理均线多头排列信号"""
        spot_df = self.processed_data.get('processed_spot_data', pd.DataFrame())
        if spot_df.empty:
            return pd.DataFrame()

        # 使用之前抓取的 K 线数据来计算均线
        # 由于 K 线抓取非常耗时，此处我们只针对 A 股实时行情中非 ST, 非停牌的股票进行 K 线数据获取和计算

        # 筛选条件：1. 非 ST 股 (名称中不含 *ST) 2. 涨跌幅不为 0（排除停牌）
        filtered_spot_df = spot_df[
            (~spot_df['股票简称'].str.contains('\*ST', na=False)) &
            (spot_df['涨跌幅'] != 0.0)
        ].copy()

        # 选取股票代码进行计算
        symbols = filtered_spot_df['股票代码'].tolist()
        results = []

        print(f"\n--- 2.2. 开始计算均线多头排列 ({len(symbols)} 支股票) ---")

        def check_xstp(symbol: str) -> Dict[str, Any]:
            """检查个股是否满足均线多头排列（MA5 > MA10 > MA20）"""
            k_df = DataFetcher()._fetch_daily_k_data(symbol)
            
            if k_df.empty or len(k_df) < 20: # 至少需要 20 天数据计算 MA20
                return {'股票代码': symbol, 'XSTP_Signal': False, 'MA5': np.nan, 'MA10': np.nan, 'MA20': np.nan}

            # 使用 pandas_ta 计算均线
            k_df.ta.sma(length=5, append=True, col_names=('MA5',))
            k_df.ta.sma(length=10, append=True, col_names=('MA10',))
            k_df.ta.sma(length=20, append=True, col_names=('MA20',))

            # 取最新的均线值
            last_row = k_df.iloc[-1]
            ma5, ma10, ma20 = last_row['MA5'], last_row['MA10'], last_row['MA20']

            # 均线多头排列判断：MA5 > MA10 > MA20 且 MA5 向上
            # 注意：此处只判断大小关系，不判断方向，简化处理
            is_xstp = (ma5 > ma10) and (ma10 > ma20)

            return {'股票代码': symbol, 'XSTP_Signal': is_xstp, 'MA5': ma5, 'MA10': ma10, 'MA20': ma20}


        # 多线程并行计算
        with ThreadPoolExecutor(max_workers=CFG.MAX_WORKERS) as executor:
            future_to_symbol = {executor.submit(check_xstp, sym): sym for sym in symbols}
            for i, future in enumerate(as_completed(future_to_symbol)):
                # 打印进度 (每处理 100 个打印一次)
                if (i + 1) % 100 == 0:
                    print(f"  -> 已处理 {i + 1} / {len(symbols)} 支股票...")
                try:
                    results.append(future.result())
                except Exception as exc:
                    print(f"[WARN] 均线计算异常: {exc}")

        # 合并结果
        xstp_df = pd.DataFrame(results)
        
        # 筛选出满足条件的股票
        xstp_df = xstp_df[xstp_df['XSTP_Signal'] == True]
        
        # 合并回实时行情数据，获取股票简称和最新价等信息
        xstp_final_df = xstp_df.merge(
            filtered_spot_df[['股票代码', '股票简称', '最新价', '涨跌幅']],
            on='股票代码',
            how='left'
        )
        
        # 排序并保留所需列
        xstp_final_df = xstp_final_df.sort_values(by='涨跌幅', ascending=False)
        required_cols = ['股票代码', '股票简称', '最新价', '涨跌幅', 'MA5', 'MA10', 'MA20']
        
        print(f"--- 2.2. 均线多头排列计算完成。找到 {len(xstp_final_df)} 支股票。 ---")
        return xstp_final_df[required_cols] if not xstp_final_df.empty else pd.DataFrame()


    def _calculate_ta_signals(self) -> Dict[str, pd.DataFrame]:
        """计算 MACD, KDJ, CCI, RSI, BOLL 等技术指标信号"""
        
        spot_df = self.processed_data.get('processed_spot_data', pd.DataFrame())
        if spot_df.empty:
            return {}

        # 筛选条件：同均线多头排列
        filtered_spot_df = spot_df[
            (~spot_df['股票简称'].str.contains('\*ST', na=False)) &
            (spot_df['涨跌幅'] != 0.0)
        ].copy()

        symbols = filtered_spot_df['股票代码'].tolist()
        ta_signals: Dict[str, List[Dict[str, Any]]] = {
            'MACD': [], 'KDJ': [], 'CCI': [], 'RSI': [], 'BOLL': []
        }

        print(f"\n--- 2.3. 开始计算技术指标信号 ({len(symbols)} 支股票) ---")

        def check_ta_signals(symbol: str) -> Dict[str, Any]:
            """计算个股的技术指标信号"""
            k_df = DataFetcher()._fetch_daily_k_data(symbol)
            if k_df.empty:
                return {'股票代码': symbol}

            signals = {'股票代码': symbol}

            # --- MACD 金叉 (DIFF 上穿 DEA) ---
            if len(k_df) >= 26: # MACD 需要至少 26 根 K 线
                # ta.macd 默认使用 fast=12, slow=26, signal=9
                macd_df = k_df.ta.macd(append=True)
                # 列名：MACDh_12_26_9 (柱线), MACD_12_26_9 (DIFF), MACDs_12_26_9 (DEA)
                diff = macd_df.iloc[-1]['MACD_12_26_9']
                dea = macd_df.iloc[-1]['MACDs_12_26_9']
                prev_diff = macd_df.iloc[-2]['MACD_12_26_9']
                prev_dea = macd_df.iloc[-2]['MACDs_12_26_9']
                # DIFF 上穿 DEA
                if prev_diff <= prev_dea and diff > dea:
                    signals['MACD'] = {'MACD_DIFF': diff, 'MACD_DEA': dea, 'MACD_Signal': '金叉'}

            # --- KDJ 超卖金叉 (J < 20 且 J 上穿 K) ---
            if len(k_df) >= 14: # KDJ 默认需要 14 根 K 线
                # ta.stoch 默认使用 k=14, d=3, smooth_k=3
                kdj_df = k_df.ta.stoch(append=True)
                # 列名：STOCHk_14_3_3 (K), STOCHd_14_3_3 (D)
                k = kdj_df.iloc[-1]['STOCHk_14_3_3']
                d = kdj_df.iloc[-1]['STOCHd_14_3_3']
                j = 3 * k - 2 * d # J 值计算
                
                prev_k = kdj_df.iloc[-2]['STOCHk_14_3_3']
                prev_d = kdj_df.iloc[-2]['STOCHd_14_3_3']
                prev_j = 3 * prev_k - 2 * prev_d

                # 超卖区 (J < 20) 且 J 上穿 K (简化为 J 上穿 K 且 J 在 20 附近)
                # 此处使用 K 上穿 D 且 K/D/J 均在 20 以下作为超卖金叉的信号
                if k < 25 and d < 25 and prev_k <= prev_d and k > d:
                    signals['KDJ'] = {'KDJ_K': k, 'KDJ_D': d, 'KDJ_J': j, 'KDJ_Signal': '超卖金叉'}

            # --- CCI 超卖 (CCI < -100) ---
            if len(k_df) >= 14: # CCI 默认需要 14 根 K 线
                cci_df = k_df.ta.cci(append=True)
                # 列名：CCI_14_0.015
                cci = cci_df.iloc[-1]['CCI_14_0.015']
                if cci < -100:
                    signals['CCI'] = {'CCI_Value': cci, 'CCI_Signal': '超卖'}

            # --- RSI 超卖 (RSI < 30) ---
            if len(k_df) >= 14: # RSI 默认需要 14 根 K 线
                rsi_df = k_df.ta.rsi(append=True)
                # 列名：RSI_14
                rsi = rsi_df.iloc[-1]['RSI_14']
                if rsi < 30:
                    signals['RSI'] = {'RSI_Value': rsi, 'RSI_Signal': '超卖'}
            
            # --- BOLL 低波动 (带宽窄) ---
            if len(k_df) >= 20: # BOLL 默认需要 20 根 K 线
                # ta.bbands 默认 length=20, std=2.0
                bbands_df = k_df.ta.bbands(append=True)
                # 列名：BBL_20_2.0 (下轨), BBU_20_2.0 (上轨), BBB_20_2.0 (带宽百分比)
                # 带宽百分比 (BBB) 越小表示波动率越低
                bbb = bbands_df.iloc[-1]['BBB_20_2.0']
                # 设定一个阈值，例如低于 5% 认为是低波动
                if bbb < 5.0:
                    signals['BOLL'] = {'BOLL_Bandwidth': bbb, 'BOLL_Signal': '低波'}

            return signals

        # 多线程并行计算
        with ThreadPoolExecutor(max_workers=CFG.MAX_WORKERS) as executor:
            future_to_symbol = {executor.submit(check_ta_signals, sym): sym for sym in symbols}
            for i, future in enumerate(as_completed(future_to_symbol)):
                if (i + 1) % 100 == 0:
                    print(f"  -> 已处理 {i + 1} / {len(symbols)} 支股票...")
                try:
                    res = future.result()
                    symbol = res['股票代码']
                    
                    # 将结果分发到对应的信号列表中
                    for signal_key in ['MACD', 'KDJ', 'CCI', 'RSI', 'BOLL']:
                        if signal_key in res:
                            signal_data = res[signal_key]
                            # 合并行情数据
                            spot_info = filtered_spot_df[filtered_spot_df['股票代码'] == symbol].iloc[0]
                            signal_data['股票代码'] = symbol
                            signal_data['股票简称'] = spot_info['股票简称']
                            signal_data['最新价'] = spot_info['最新价']
                            signal_data['涨跌幅'] = spot_info['涨跌幅']
                            ta_signals[signal_key].append(signal_data)
                            
                except Exception as exc:
                    # print(f"[WARN] TA 指标计算异常: {exc}")
                    pass # 忽略单个股票的计算错误

        # 转换为 DataFrame
        final_ta_signals = {}
        for key, data_list in ta_signals.items():
            df = pd.DataFrame(data_list)
            if not df.empty:
                df = df.sort_values(by='涨跌幅', ascending=False)
            final_ta_signals[key] = df
            print(f"  -> {key} 信号找到 {len(df)} 支股票。")


        print("--- 2.3. 技术指标信号计算完成 ---")
        return final_ta_signals

    def _consolidate_data(self) -> pd.DataFrame:
        """整合所有数据源，生成一个综合报告表"""
        print("\n--- 3. 开始整合数据 ---")
        
        # 1. 获取所有独特的股票代码
        all_codes = set()
        
        # 实时行情作为基准
        spot_df = self.processed_data.get('processed_spot_data', pd.DataFrame())
        if spot_df.empty:
            print("[WARN] 实时行情数据为空，无法生成综合报告。")
            return pd.DataFrame()

        all_codes.update(spot_df['股票代码'].tolist())
        
        # 2. 初始化综合报告 DataFrame
        consolidated_df = spot_df[['股票代码', '股票简称', '最新价', '涨跌幅']].copy()
        consolidated_df = consolidated_df.set_index('股票代码')

        # 3. 添加研报评分 (Count)
        report_df = self.processed_data.get('processed_main_report', pd.DataFrame())
        report_counts = report_df.groupby('股票代码').size().reset_index(name='研报数量')
        report_counts = report_counts.set_index('股票代码')
        consolidated_df = consolidated_df.merge(report_counts, left_index=True, right_index=True, how='left')
        consolidated_df['研报数量'] = consolidated_df['研报数量'].fillna(0).astype(int)

        # 4. 添加强势股池、连续上涨、量价齐升、持续放量 (Flag)
        flag_sources = {
            '强势股池': self.processed_data.get('processed_strong_stocks', pd.DataFrame()),
            '连续上涨': self.processed_data.get('processed_consecutive_rise', pd.DataFrame()),
            '量价齐升': self.processed_data.get('processed_ljqs', pd.DataFrame()),
            '持续放量': self.processed_data.get('processed_cxfl', pd.DataFrame()),
        }
        
        for name, df in flag_sources.items():
            if not df.empty:
                codes = df['股票代码'].unique()
                consolidated_df[name] = consolidated_df.index.isin(codes).astype(int)
            else:
                consolidated_df[name] = 0

        # 5. 添加技术指标信号 (Flag)
        ta_signals = self._calculate_ta_signals()
        
        # 均线多头排列
        xstp_df = self.processed_data.get('processed_xstp_signal', pd.DataFrame())
        if not xstp_df.empty:
             consolidated_df['均线多头排列'] = consolidated_df.index.isin(xstp_df['股票代码'].unique()).astype(int)
        else:
            consolidated_df['均线多头排列'] = 0

        # 其他 TA 指标
        ta_names = {
            'MACD': 'MACD金叉',
            'KDJ': 'KDJ超卖金叉',
            'CCI': 'CCI超卖',
            'RSI': 'RSI超卖',
            'BOLL': 'BOLL低波'
        }
        for ta_key, col_name in ta_names.items():
            df = ta_signals.get(ta_key, pd.DataFrame())
            if not df.empty:
                consolidated_df[col_name] = consolidated_df.index.isin(df['股票代码'].unique()).astype(int)
            else:
                consolidated_df[col_name] = 0

        # 6. 添加行业前十成分股 (Flag)
        industry_cons_df = self.processed_data.get('processed_top_industry_cons', pd.DataFrame())
        if not industry_cons_df.empty:
             consolidated_df['前十板块成分'] = consolidated_df.index.isin(industry_cons_df['股票代码'].unique()).astype(int)
        else:
            consolidated_df['前十板块成分'] = 0


        # 7. 计算综合得分 (简单加权求和)
        score_cols = [
            '研报数量', '强势股池', '连续上涨', '量价齐升', '持续放量', 
            '均线多头排列', 'MACD金叉', 'KDJ超卖金叉', 'CCI超卖', 'RSI超卖', 'BOLL低波',
            '前十板块成分'
        ]
        
        # 将研报数量分数化 (数量 >= 2 计 1 分, 数量 >= 1 计 0.5 分)
        consolidated_df['研报数量分'] = consolidated_df['研报数量'].apply(lambda x: 1 if x >= 2 else (0.5 if x >= 1 else 0))
        
        # 计算总分 (其他指标计 1 分)
        score_cols_flags = [col for col in score_cols if col != '研报数量'] # 排除原始研报数量列
        consolidated_df['总分'] = consolidated_df['研报数量分'] + consolidated_df[score_cols_flags].sum(axis=1)

        # 8. 过滤和排序
        # 移除分数小于 1.5 的股票（专注于高潜力股）
        # 过滤掉涨停和跌停的股票，避免异常值
        final_df = consolidated_df[
            (consolidated_df['总分'] >= 1.5) & 
            (consolidated_df['涨跌幅'] < 9.5) & # 过滤掉即将涨停的 (防止高位站岗)
            (consolidated_df['涨跌幅'] > -9.5) # 过滤掉即将跌停的
        ].reset_index()

        final_df = final_df.sort_values(by=['总分', '涨跌幅'], ascending=[False, False])

        # 调整列顺序
        final_cols_order = ['股票代码', '股票简称', '最新价', '涨跌幅', '总分', '研报数量', 
                            '均线多头排列', 'MACD金叉', 'KDJ超卖金叉', 'CCI超卖', 'RSI超卖', 'BOLL低波',
                            '强势股池', '连续上涨', '量价齐升', '持续放量', '前十板块成分']
        
        final_df = final_df[[col for col in final_cols_order if col in final_df.columns]].copy()
        
        # 最后，移除中间计算列
        # final_df = final_df.drop(columns=['研报数量分'])

        print(f"--- 3. 数据整合完成。筛选出 {len(final_df)} 支高潜力股。 ---")
        return final_df

    def process_all_data(self) -> Dict[str, Any]:
        """执行所有数据处理步骤"""
        start_time = time.time()
        print("\n--- 2. 开始处理和计算数据 ---")
        
        # 2.1 清洗和标准化
        self._clean_and_standardize_data()
        
        # 2.2 特殊处理主力研报
        self.processed_data['processed_main_report'] = self._process_main_report()
        
        # 2.3 均线多头排列信号 (耗时操作)
        self.processed_data['processed_xstp_signal'] = self._process_xstp_signal()
        
        # 2.4 TA 指标 (耗时操作，已在数据整合中执行，此处不重复)
        # ta_signals = self._calculate_ta_signals()
        
        # 2.5 数据整合和评分
        consolidated_report = self._consolidate_data()
        self.processed_data['consolidated_report'] = consolidated_report
        
        end_time = time.time()
        print(f"--- 2. 数据处理和计算完成，耗时: {end_time - start_time:.2f} 秒 ---")
        
        return self.processed_data


# ==============================================================================
# 报告生成模块
# ==============================================================================
class ReportGenerator:
    """负责将处理后的数据输出为 Excel 报告"""

    def __init__(self, data_fetcher: DataFetcher, data_processor: DataProcessor):
        self.data_fetcher = data_fetcher
        self.data_processor = data_processor
        self.output_file = os.path.join(CFG.SAVE_DIRECTORY, f"CoreNews_Analysis_{CFG.TODAY_STR}.xlsx")
        
    def _generate_report(self, sheets_data: Dict[str, pd.DataFrame]):
        """生成 Excel 文件"""
        
        print(f"\n--- 4. 正在生成报告: {os.path.basename(self.output_file)} ---")
        writer = pd.ExcelWriter(self.output_file, engine='xlsxwriter')
        workbook = writer.book

        # 通用格式
        format_header = workbook.add_format({
            'bold': True, 'text_wrap': True, 'valign': 'top',
            'fg_color': '#D7E4BC', 'border': 1
        })
        format_center = workbook.add_format({'align': 'center'})
        format_percent = workbook.add_format({'num_format': '0.00%'})
        format_decimal = workbook.add_format({'num_format': '0.00'})
        
        for sheet_name, df in sheets_data.items():
            if df.empty:
                print(f"[WARN] 工作表 '{sheet_name}' 数据为空，跳过。")
                continue

            df.to_excel(writer, sheet_name=sheet_name, startrow=1, header=False, index=False)
            worksheet = writer.sheets[sheet_name]

            # 写入表头
            for col_num, value in enumerate(df.columns.values):
                worksheet.write(0, col_num, value, format_header)
                
            # 设置列宽和格式
            for col_num, col_name in enumerate(df.columns):
                max_len = max(df[col_name].astype(str).apply(len).max(), len(col_name))
                width = min(max(max_len + 2, 10), 40) # 最小 10，最大 40
                
                # 特殊格式处理
                if '涨跌幅' in col_name or '换手率' in col_name or '带宽' in col_name:
                    worksheet.set_column(col_num, col_num, width, format_percent)
                elif '最新价' in col_name or '价格' in col_name or 'MA' in col_name or 'DEA' in col_name or 'DIFF' in col_name:
                    worksheet.set_column(col_num, col_num, width, format_decimal)
                elif '股票代码' in col_name or '代码' in col_name:
                    worksheet.set_column(col_num, col_num, width, format_center)
                elif '股票简称' in col_name or '名称' in col_name:
                    worksheet.set_column(col_num, col_num, width + 5) # 简称略宽
                elif '标题' in col_name:
                    worksheet.set_column(col_num, col_num, 60) # 标题最宽
                else:
                    worksheet.set_column(col_num, col_num, width)


        try:
            writer.close()
            print(f"--- 4. 报告生成成功! 文件路径: {self.output_file} ---")
        except xlsxwriter.exceptions.FileCreateError as e:
            print(f"[FATAL] 报告生成失败：文件可能被占用。请关闭 Excel 文件后重试。错误: {e}")
        except Exception as e:
            print(f"[FATAL] 报告生成过程中发生未知错误: {e}")

    def run(self):
        """主执行流程"""
        try:
            # 1. 抓取原始数据
            raw_data = self.data_fetcher.fetch_all_data()

            # 2. 处理数据
            processed_data = self.data_processor.process_all_data()

            # 3. 提取特殊处理后的数据
            spot_df = processed_data.get('processed_spot_data', pd.DataFrame())
            processed_xstp_df = processed_data.get('processed_xstp_signal', pd.DataFrame())
            consolidated_report = processed_data.get('consolidated_report', pd.DataFrame())
            
            # 4. 重新计算 TA 信号（为了在子表中展示，需单独获取）
            ta_signals = self.data_processor._calculate_ta_signals()


            # 5. 准备报告数据
            sheets_data = {
                '数据汇总': consolidated_report,  # 替换为数据汇总表
                '主力研报筛选': processed_data.get('processed_main_report', pd.DataFrame()),
                '均线多头排列': processed_xstp_df,  # 使用处理后且过滤后的数据
                '实时行情': spot_df,  # 使用清洗后的数据
                '市场资金流向': raw_data.get('market_fund_flow_raw', pd.DataFrame()),
                '强势股池': raw_data.get('strong_stocks_raw', pd.DataFrame()),
                '连续上涨': raw_data.get('consecutive_rise_raw', pd.DataFrame()),
                '量价齐升': raw_data.get('ljqs_raw', pd.DataFrame()),
                '持续放量': raw_data.get('cxfl_raw', pd.DataFrame()),
                'MACD金叉': ta_signals.get('MACD', pd.DataFrame()),
                'KDJ超卖金叉': ta_signals.get('KDJ', pd.DataFrame()),
                'CCI超卖': ta_signals.get('CCI', pd.DataFrame()),
                'RSI超卖': ta_signals.get('RSI', pd.DataFrame()),
                'BOLL低波': ta_signals.get('BOLL', pd.DataFrame()),
                '前十板块成分股': raw_data.get('top_industry_cons_df', pd.DataFrame()),
            }

            # 6. 生成报告
            self._generate_report(sheets_data)

        except Exception as e:
            print(f"\n[FATAL] 致命错误：程序运行失败。{e}")


# ==============================================================================
# 主入口
# ==============================================================================
if __name__ == "__main__":
    
    start_time_total = time.time()
    print("==============================================================================")
    print(f"               CoreNews 股票分析与报告生成工具 v5.0")
    print(f"               当前日期: {CFG.TODAY_STR}")
    print("==============================================================================")
    
    # 实例化数据抓取和处理对象
    data_fetcher = DataFetcher()
    # 在抓取之前，先实例化 processor, 但传入的 raw_data 是空的，仅为了在 processor 中使用 _calculate_ta_signals
    # 由于 processor 的初始化依赖 raw_data，这里需要调整执行顺序或在 processor 中再获取数据。
    # 最佳实践：抓取完成后再实例化 processor
    
    # 1. 抓取数据 (这步必须先执行)
    raw_data = data_fetcher.fetch_all_data()

    # 2. 处理数据 (传入抓取到的原始数据)
    data_processor = DataProcessor(raw_data)
    processed_data = data_processor.process_all_data()
    
    # 3. 生成报告
    report_generator = ReportGenerator(data_fetcher, data_processor)
    report_generator.run()

    end_time_total = time.time()
    print("==============================================================================")
    print(f"所有任务完成! 总耗时: {end_time_total - start_time_total:.2f} 秒")
    print("==============================================================================")
