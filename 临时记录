import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
from typing import Callable, Dict, Any, List
import pandas_ta as ta
import numpy as np
import xlsxwriter

# å¿½ç•¥ pandas çš„ SettingWithCopyWarning
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)


# ==============================================================================
# æ ¸å¿ƒå·¥å…·å‡½æ•°å’Œé…ç½®
# ==============================================================================
class Config:
    """ç¨‹åºé…ç½®ç±»"""

    def __init__(self):
        self.HOME_DIRECTORY = os.path.expanduser('~')
        self.SAVE_DIRECTORY = os.path.join(self.HOME_DIRECTORY, 'Downloads', 'CoreNews_Reports')
        self.TEMP_DATA_DIRECTORY = os.path.join(self.SAVE_DIRECTORY, 'ShareData')
        self.DATA_FETCH_RETRIES = 3
        self.DATA_FETCH_DELAY = 5  #
        self.MAX_WORKERS = 15
        self.CODE_ALIASES = {'ä»£ç ': 'è‚¡ç¥¨ä»£ç ', 'è¯åˆ¸ä»£ç ': 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ä»£ç ': 'è‚¡ç¥¨ä»£ç '}
        # åˆ«åå·²åŒ…å«æ‰€æœ‰å¸¸è§åç§°
        self.NAME_ALIASES = {'åç§°': 'è‚¡ç¥¨ç®€ç§°', 'è‚¡ç¥¨åç§°': 'è‚¡ç¥¨ç®€ç§°', 'è‚¡ç¥¨ç®€ç§°': 'è‚¡ç¥¨ç®€ç§°', 'ç®€ç§°': 'è‚¡ç¥¨ç®€ç§°',
                             'ç®€': 'è‚¡ç¥¨ç®€ç§°', 'è¯åˆ¸åç§°': 'è‚¡ç¥¨ç®€ç§°'}
        # === ä»·æ ¼åˆ«åä¿®å¤ v5ï¼šæ¶µç›–æ›´å¤šå®æ—¶è¡Œæƒ…ä»·æ ¼å­—æ®µ ===
        self.PRICE_ALIASES = {'æœ€æ–°ä»·': 'æœ€æ–°ä»·', 'å¼€ç›˜': 'ä»Šå¼€', 'æ”¶ç›˜': 'æ˜¨æ”¶', 'æœ€é«˜': 'æœ€é«˜', 'æœ€ä½': 'æœ€ä½'}


def format_stock_code(code: str) -> str:
    """æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼Œç¡®ä¿æ˜¯ 6 ä½å­—ç¬¦ä¸²ï¼Œå¹¶åœ¨æ·±å¸‚ä»£ç å‰åŠ  'sz'ï¼Œæ²ªå¸‚ä»£ç å‰åŠ  'sh'ã€‚"""
    code = str(code).zfill(6)
    if code.startswith(('00', '30')):
        return f'sz{code}'
    elif code.startswith(('60', '68')):
        return f'sh{code}'
    elif code.startswith('8'): # åŒ—äº¤æ‰€
        return f'bj{code}'
    return code


# --- NEW FUNCTION: è®¡ç®— MACD åŠ¨æ€çŠ¶æ€ ---
def calculate_macd_dynamic_status(df: pd.DataFrame, diff_col: str, prefix: str) -> pd.DataFrame:
    """
    è®¡ç®— MACD DIF çº¿çš„åŠ¨æ€çŠ¶æ€ï¼ˆæ–œç‡å’ŒåŒºåŸŸï¼‰ã€‚

    å‚æ•°:
    - df: åŒ…å« MACD DIF çº¿çš„ DataFrameã€‚
    - diff_col: MACD DIF çº¿çš„åˆ—åï¼ˆä¾‹å¦‚ï¼š'MACD_12_26_DIF'ï¼‰ã€‚
    - prefix: ç”¨äºç»“æœåˆ—å‘½åï¼Œå¦‚ 'MACD_12269'ã€‚

    è¿”å›:
    - åŒ…å« 'åŠ¨æ€çŠ¶æ€' (DYN) å’Œ 'DIF æ–œç‡' (SLOPE) çš„ DataFrame (ä»…è¿”å›æœ€æ–°ä¸€è¡Œ)ã€‚
    """
    # 1. è®¡ç®— DIF çº¿çš„æ–œç‡ (ä¸€é˜¶å·®åˆ†)
    slope_col = f'{prefix}_SLOPE'
    # ä½¿ç”¨ diff(periods=1) è®¡ç®—æ–œç‡
    df[slope_col] = df[diff_col].diff(periods=1)

    # 2. å®šä¹‰åŠ¨æ€çŠ¶æ€åˆ¤æ–­å‡½æ•° (ä½¿ç”¨å‘é‡åŒ–æ“ä½œ np.select)
    status_col = f'{prefix}_DYN'

    # å®šä¹‰æ¡ä»¶
    conditions = [
        # 1. åŠ¨èƒ½åŠ é€Ÿ: DIF > 0 ä¸” Slope >= 0 (å¤„äºå¼ºåŠ¿åŒºåŸŸï¼ŒåŠ¨èƒ½å¢å¼ºæˆ–ä¿æŒ)
        (df[diff_col] > 0) & (df[slope_col] >= 0),
        # 2. åŠ¨èƒ½è¡°å‡ (è­¦ç¤º): DIF > 0 ä¸” Slope < 0 (å¤„äºå¼ºåŠ¿åŒºåŸŸï¼ŒåŠ¨èƒ½å¼€å§‹å‡å¼±)
        (df[diff_col] > 0) & (df[slope_col] < 0),
        # 3. åŠ¨èƒ½ç­‘åº•: DIF < 0 ä¸” Slope >= 0 (å¤„äºå¼±åŠ¿åŒºåŸŸï¼ŒåŠ¨èƒ½å¼€å§‹å¢å¼ºæˆ–ä¿æŒ)
        (df[diff_col] < 0) & (df[slope_col] >= 0),
        # 4. åŠ¨èƒ½æ¶åŒ–: DIF < 0 ä¸” Slope < 0 (å¤„äºå¼±åŠ¿åŒºåŸŸï¼ŒåŠ¨èƒ½åŠ é€Ÿä¸‹é™)
        (df[diff_col] < 0) & (df[slope_col] < 0)
    ]

    # å®šä¹‰ç»“æœ
    choices = [
        'ğŸŸ¢ åŠ¨èƒ½åŠ é€Ÿ',
        'âš ï¸ åŠ¨èƒ½è¡°å‡',
        'ğŸŸ¡ åŠ¨èƒ½ç­‘åº•',
        'ğŸ”´ åŠ¨èƒ½æ¶åŒ–'
    ]

    # åº”ç”¨é€‰æ‹©é€»è¾‘
    df[status_col] = np.select(conditions, choices, default='---')

    # 3. æå–æœ€æ–°çš„ç»“æœ (å³å‰ä¸€ä¸ªäº¤æ˜“æ—¥æ”¶ç›˜æ•°æ®)
    latest_result = df.tail(1)[[status_col, slope_col]]

    # 4. é‡å‘½ååˆ—å¹¶è¿”å›
    latest_result.columns = [status_col, slope_col]
    return latest_result.reset_index(drop=True)
# ==============================================================================


class StockAnalyzer:
    """è‚¡ç¥¨æ•°æ®è·å–ã€åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, start_date: str = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d'),
                 end_date: str = datetime.now().strftime('%Y%m%d')):
        self.config = Config()
        self.start_date = start_date
        self.end_date = end_date
        self._ensure_directories()
        self.all_stock_codes = []  # å­˜å‚¨æ‰€æœ‰æœ‰æ•ˆè‚¡ç¥¨ä»£ç 
        self.all_stock_names = {}  # å­˜å‚¨è‚¡ç¥¨ä»£ç åˆ°åç§°çš„æ˜ å°„
        self.stock_link_base = "https://hybrid.gelonghui.com/stock-check/" # è‚¡ç¥¨é“¾æ¥åŸºç¡€


    def _ensure_directories(self):
        """ç¡®ä¿ä¿å­˜å’Œä¸´æ—¶æ•°æ®ç›®å½•å­˜åœ¨"""
        os.makedirs(self.config.SAVE_DIRECTORY, exist_ok=True)
        os.makedirs(self.config.TEMP_DATA_DIRECTORY, exist_ok=True)
        print(f"æ•°æ®ä¿å­˜ç›®å½•: {self.config.SAVE_DIRECTORY}")
        print(f"ç¼“å­˜æ•°æ®ç›®å½•: {self.config.TEMP_DATA_DIRECTORY}")


    def _get_file_path(self, func_name: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        return os.path.join(self.config.TEMP_DATA_DIRECTORY, f"{func_name}.pkl")


    def _load_data_from_cache(self, func_name: str) -> pd.DataFrame | None:
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        file_path = self._get_file_path(func_name)
        if os.path.exists(file_path):
            try:
                # æ£€æŸ¥æ–‡ä»¶æ—¶é—´æˆ³ï¼Œå¦‚æœè¶…è¿‡å½“å¤©ï¼Œåˆ™è§†ä¸ºè¿‡æœŸ
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path)).date()
                if file_time == datetime.now().date():
                    return pd.read_pickle(file_path)
            except Exception as e:
                print(f"è¯»å–ç¼“å­˜æ–‡ä»¶ {func_name}.pkl å¤±è´¥: {e}")
        return None


    def _save_data_to_cache(self, df: pd.DataFrame, func_name: str):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        file_path = self._get_file_path(func_name)
        try:
            df.to_pickle(file_path)
        except Exception as e:
            print(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶ {func_name}.pkl å¤±è´¥: {e}")


    def _clean_and_standardize(self, df: pd.DataFrame, is_history: bool = False) -> pd.DataFrame:
        """æ¸…æ´—å’Œæ ‡å‡†åŒ– DataFrame çš„åˆ—åã€æ ¼å¼å’Œè¿‡æ»¤ ST è‚¡"""
        if df.empty:
            return df

        # 1. é‡å‘½ååˆ—å
        df.rename(columns=self.config.CODE_ALIASES, inplace=True)
        df.rename(columns=self.config.NAME_ALIASES, inplace=True)

        # 2. æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
        if 'è‚¡ç¥¨ä»£ç ' in df.columns:
            # å»é™¤å¯èƒ½çš„å‰ç¼€ï¼Œç¡®ä¿æ˜¯çº¯æ•°å­—
            df['è‚¡ç¥¨ä»£ç '] = df['è‚¡ç¥¨ä»£ç '].apply(lambda x: str(x).replace('sh', '').replace('sz', '').replace('bj', '').zfill(6))
            
            # è¿‡æ»¤ ST è‚¡å’Œé€€å¸‚è‚¡ (*ST, S*ST, ST, é€€)
            if 'è‚¡ç¥¨ç®€ç§°' in df.columns:
                df = df[~df['è‚¡ç¥¨ç®€ç§°'].str.contains(r'(\*ST|S\*ST|ST|é€€|N)', na=False, regex=True)].copy()
                
            # é‡æ–°æ·»åŠ å‰ç¼€ï¼ˆä»…é’ˆå¯¹éå†å²æ•°æ®æˆ–éœ€è¦å‰ç¼€çš„æ­¥éª¤ï¼‰
            if not is_history:
                 df['è‚¡ç¥¨ä»£ç '] = df['è‚¡ç¥¨ä»£ç '].apply(format_stock_code)


        # 3. ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
        if 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')

        return df


    def _safe_ak_fetch(self, func: Callable, func_name: str, *args, **kwargs) -> pd.DataFrame:
        """å®‰å…¨çš„ Akshare æ•°æ®è·å–ã€ç¼“å­˜å’Œé‡è¯•æœºåˆ¶"""
        
        df = self._load_data_from_cache(func_name)
        if df is not None:
            print(f"âœ… ä»ç¼“å­˜åŠ è½½ {func_name} æ•°æ®æˆåŠŸ.")
            return self._clean_and_standardize(df)
        
        print(f"â³ å°è¯•è·å– {func_name} æ•°æ®...")
        
        for attempt in range(self.config.DATA_FETCH_RETRIES):
            try:
                df = func(*args, **kwargs)
                if df is not None and not df.empty:
                    df = self._clean_and_standardize(df)
                    self._save_data_to_cache(df, func_name)
                    print(f"âœ… è·å– {func_name} æ•°æ®æˆåŠŸ (å°è¯• {attempt + 1}/{self.config.DATA_FETCH_RETRIES}).")
                    return df
                else:
                    print(f"âš ï¸ {func_name} è¿”å›ç©ºæ•°æ® (å°è¯• {attempt + 1}/{self.config.DATA_FETCH_RETRIES}).")

            except Exception as e:
                print(f"âŒ è·å– {func_name} å¤±è´¥ (å°è¯• {attempt + 1}/{self.config.DATA_FETCH_RETRIES}): {e}")
                time.sleep(self.config.DATA_FETCH_DELAY)
        
        print(f"ğŸ”´ æœ€ç»ˆè·å– {func_name} æ•°æ®å¤±è´¥ã€‚è¿”å›ç©º DataFrame.")
        return pd.DataFrame()


    def _get_all_raw_data(self) -> Dict[str, pd.DataFrame]:
        """è·å–æ‰€æœ‰éœ€è¦çš„åŸå§‹æ•°æ®"""
        raw_data = {}
        
        # 1. è·å–åŸºç¡€è‚¡ç¥¨åˆ—è¡¨ (ç”¨äºè·å–å†å²æ•°æ®)
        stock_list_raw = self._safe_ak_fetch(
            ak.stock_info_a_code_name,
            'stock_info_a_code_name'
        )
        if stock_list_raw.empty or 'è‚¡ç¥¨ä»£ç ' not in stock_list_raw.columns:
            raise ValueError("æ— æ³•è·å–åŸºç¡€è‚¡ç¥¨åˆ—è¡¨ï¼Œç¨‹åºç»ˆæ­¢ã€‚")

        self.all_stock_codes = stock_list_raw['è‚¡ç¥¨ä»£ç '].apply(lambda x: str(x).zfill(6)).tolist()
        self.all_stock_names = dict(zip(stock_list_raw['è‚¡ç¥¨ä»£ç '], stock_list_raw['è‚¡ç¥¨ç®€ç§°']))

        # 2. è·å–å®æ—¶è¡Œæƒ…
        raw_data['spot_raw'] = self._safe_ak_fetch(
            ak.stock_zh_a_spot_em,
            'stock_zh_a_spot_em'
        )
        
        # 3. è·å–å…¶ä»–ç­›é€‰æ•°æ® (ä½¿ç”¨æœ€æ–°çš„æ¥å£)
        # ä¸»åŠ›ç ”æŠ¥
        raw_data['main_report_raw'] = self._safe_ak_fetch(
            ak.stock_research_report_info_juyuan,
            'stock_research_report_info_juyuan'
        )
        
        # å‡çº¿å¤šå¤´æ’åˆ—
        raw_data['xstp_raw'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_xstp_em,
            'stock_a_stat_deal_daily_xstp_em'
        )
        
        # å¸‚åœºèµ„é‡‘æµå‘ (5æ—¥)
        raw_data['market_fund_flow_raw'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_market_fund_flow_em,
            'market_fund_flow_5d',
            start_date=self.start_date
        )

        # å¸‚åœºèµ„é‡‘æµå‘ (10æ—¥)
        raw_data['market_fund_flow_raw_10'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_market_fund_flow_em,
            'market_fund_flow_10d',
            start_date=self.start_date,
            period="10æ—¥"
        )

        # å¸‚åœºèµ„é‡‘æµå‘ (20æ—¥)
        raw_data['market_fund_flow_raw_20'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_market_fund_flow_em,
            'market_fund_flow_20d',
            start_date=self.start_date,
            period="20æ—¥"
        )
        
        # å¼ºåŠ¿è‚¡æ± 
        raw_data['strong_stocks_raw'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_strong_stocks_em,
            'strong_stocks_raw'
        )

        # è¿ç»­ä¸Šæ¶¨
        raw_data['consecutive_rise_raw'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_consecutive_rise_em,
            'consecutive_rise_raw'
        )

        # é‡ä»·é½å‡
        raw_data['ljqs_raw'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_ljqs_em,
            'ljqs_raw'
        )

        # æŒç»­æ”¾é‡
        raw_data['cxfl_raw'] = self._safe_ak_fetch(
            ak.stock_a_stat_deal_daily_cxfl_em,
            'cxfl_raw'
        )
        
        # å‰åæ¿å—æˆåˆ†è‚¡
        raw_data['top10_board_stocks_raw'] = self._safe_ak_fetch(
            ak.stock_board_concept_top_10_em,
            'top10_board_stocks_raw'
        )


        return raw_data


    # --- MACD è®¡ç®—ï¼ˆåŸæœ‰çš„è‡ªå®šä¹‰å‡½æ•°ï¼‰ ---
    def _custom_macd(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        åœ¨ DataFrame ä¸­è®¡ç®— MACD æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ ‡å‡† (12, 26, 9) å’ŒåŠ é€Ÿ (6, 13, 5) å‘¨æœŸã€‚
        """
        if df.empty or 'æ”¶ç›˜' not in df.columns:
            return df
        
        # ç¡®ä¿ 'æ”¶ç›˜' åˆ—æ˜¯æ•°å€¼ç±»å‹
        df['æ”¶ç›˜'] = pd.to_numeric(df['æ”¶ç›˜'], errors='coerce')
        df.dropna(subset=['æ”¶ç›˜'], inplace=True)
        if df.empty:
            return df

        # æ ‡å‡† MACD (12, 26, 9)
        macd_standard = df.ta.macd(close='æ”¶ç›˜', fast=12, slow=26, signal=9, append=True)
        if macd_standard is not None and not macd_standard.empty:
            macd_standard.columns = ['MACD_12_26_MACD', 'MACD_12_26_HIST', 'MACD_12_26_DIF']
            df = pd.concat([df.reset_index(drop=True), macd_standard.reset_index(drop=True)], axis=1)

        # åŠ é€Ÿ MACD (6, 13, 5)
        macd_accelerated = df.ta.macd(close='æ”¶ç›˜', fast=6, slow=13, signal=5, append=True)
        if macd_accelerated is not None and not macd_accelerated.empty:
            macd_accelerated.columns = ['MACD_6_13_MACD', 'MACD_6_13_HIST', 'MACD_6_13_DIF']
            df = pd.concat([df, macd_accelerated], axis=1)
            
        return df

    # --- NEW FUNCTION: æå– MACD å½“å‰å€¼ ---
    def _extract_current_macd_values(self, df: pd.DataFrame, diff_col: str, prefix: str) -> Dict[str, Any]:
        """
        æå–å½“å‰æœ€æ–°çš„ MACD (DIF) å€¼ã€‚
        """
        value_col = f'{prefix}_DIF'
        if diff_col in df.columns:
            current_value = df[diff_col].iloc[-1]
            # ä»…è¿”å›æœ€æ–°çš„é NaN å€¼ (å¦‚æœæœ€åä¸€è¡Œæ˜¯ NaN)
            if pd.isna(current_value):
                 current_value = df[diff_col].dropna().iloc[-1] if not df[diff_col].dropna().empty else np.nan

            return {'è‚¡ç¥¨ä»£ç ': df['è‚¡ç¥¨ä»£ç '].iloc[-1], value_col: current_value}
        return {}


    def _fetch_hist_data(self, code: str) -> pd.DataFrame:
        """è·å–å•ä¸ªè‚¡ç¥¨çš„å†å²æ•°æ®ï¼Œå¹¶è¿›è¡ŒåŸºæœ¬æ¸…æ´—å’Œ MACD è®¡ç®—"""
        print(f"    - æ­£åœ¨è·å– {code} å†å²æ•°æ®...")
        # å†å²æ•°æ®ç¼“å­˜æ–‡ä»¶åä½¿ç”¨ code
        file_path = self._get_file_path(f'hist_{code}')
        df = self._load_data_from_cache(f'hist_{code}')
        
        if df is None:
            try:
                # å†å²æ•°æ®è·å–ä¸å¸¦å‰ç¼€çš„çº¯æ•°å­—ä»£ç 
                pure_code = code.replace('sh', '').replace('sz', '').replace('bj', '')
                
                # è·å–å‰å¤æƒå†å²æ•°æ®
                df = ak.stock_zh_a_hist(symbol=pure_code, period="daily", start_date=self.start_date, 
                                        end_date=self.end_date, adjust="qfq")

                if df.empty:
                    return pd.DataFrame()

                # åŸºæœ¬æ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼ˆis_history=True è¡¨ç¤ºä¸éœ€è¦é‡æ–°æ ¼å¼åŒ–ä»£ç å‰ç¼€ï¼‰
                df = self._clean_and_standardize(df, is_history=True)
                df['è‚¡ç¥¨ä»£ç '] = pure_code # ç¡®ä¿ä»£ç åˆ—æ˜¯çº¯æ•°å­—
                self._save_data_to_cache(df, f'hist_{code}')
            
            except Exception as e:
                print(f"    - âŒ è·å– {code} å†å²æ•°æ®å¤±è´¥: {e}")
                return pd.DataFrame()

        # ç¡®ä¿è®¡ç®— MACD/TA å‰æ•°æ®å¯ç”¨
        if df.empty:
            return pd.DataFrame()
            
        # è®¡ç®— MACD (åŸæœ‰çš„ _custom_macd)
        df = self._custom_macd(df)
        
        return df


    def _fetch_and_calculate_ta_signals(self, code: str) -> Dict[str, List[Dict]]:
        """å¹¶è¡Œè·å–å•ä¸ªè‚¡ç¥¨çš„å†å²æ•°æ®å¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ä¿¡å·"""
        
        # 1. è·å–å’Œè®¡ç®—å†å²æ•°æ®å’Œ MACD
        df = self._fetch_hist_data(code)
        if df.empty or len(df) < 35: # è‡³å°‘éœ€è¦è¶³å¤Ÿçš„æ•°æ®æ¥è®¡ç®— BOLL å’Œ MACD
            return {}

        ta_signals: Dict[str, List[Dict]] = {}
        
        # 2. MACD ä¿¡å·æå– (åŸæœ‰é€»è¾‘)
        # MACD_12269 (æ ‡å‡†)
        if 'MACD_12_26_DIF' in df.columns:
            # åŸæœ‰ MACD é‡‘å‰ä¿¡å·
            macd_12269_signal = self._extract_macd_signal(df, 'MACD_12_26_DIF', 'MACD_12_26_MACD', 'MACD_12269')
            if macd_12269_signal:
                ta_signals['MACD_12269'].append(macd_12269_signal)

        # MACD_6135 (åŠ é€Ÿ)
        if 'MACD_6_13_DIF' in df.columns:
            # åŸæœ‰ MACD é‡‘å‰ä¿¡å·
            macd_6135_signal = self._extract_macd_signal(df, 'MACD_6_13_DIF', 'MACD_6_13_MACD', 'MACD_6135')
            if macd_6135_signal:
                ta_signals['MACD_6135'].append(macd_6135_signal)


        # --- NEW CODE BLOCK START ---
        # ---------------------------
        # --- æ–°å¢ MACD å½“å‰å€¼æå– ---
        # ---------------------------
        # æå– MACD_12269 å½“å‰ DIF å€¼
        macd_val_12269 = self._extract_current_macd_values(df, 'MACD_12_26_DIF', 'MACD_12269')
        if macd_val_12269:
            ta_signals.setdefault('MACD_12269_VAL', []).append(macd_val_12269)
        
        # æå– MACD_6135 å½“å‰ DIF å€¼
        macd_val_6135 = self._extract_current_macd_values(df, 'MACD_6_13_DIF', 'MACD_6135')
        if macd_val_6135:
            ta_signals.setdefault('MACD_6135_VAL', []).append(macd_val_6135)

        # ----------------------------------------------------
        # --- æ–°å¢ MACD åŠ¨èƒ½çŠ¶æ€è®¡ç®—ä¸æå– (ä½¿ç”¨å¤–éƒ¨å‡½æ•°) ---
        # ----------------------------------------------------
        # è®¡ç®— MACD_12269 åŠ¨èƒ½çŠ¶æ€
        try:
            dyn_12269 = calculate_macd_dynamic_status(
                df.copy(), # ä¼ å…¥å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹ df
                diff_col='MACD_12_26_DIF',
                prefix='MACD_12269'
            )
            # åˆå¹¶è‚¡ç¥¨ä»£ç å’ŒåŠ¨æ€çŠ¶æ€ç»“æœ
            ta_signals.setdefault('MACD_12269_DYN', []).append(
                {'è‚¡ç¥¨ä»£ç ': code, **dyn_12269.iloc[0].to_dict()}
            )
        except Exception:
            pass

        # è®¡ç®— MACD_6135 åŠ¨èƒ½çŠ¶æ€
        try:
            dyn_6135 = calculate_macd_dynamic_status(
                df.copy(),
                diff_col='MACD_6_13_DIF',
                prefix='MACD_6135'
            )
            ta_signals.setdefault('MACD_6135_DYN', []).append(
                {'è‚¡ç¥¨ä»£ç ': code, **dyn_6135.iloc[0].to_dict()}
            )
        except Exception:
            pass
        # --- NEW CODE BLOCK END ---


        # 3. KDJã€CCIã€RSIã€BOLL ä¿¡å·æå– (åŸæœ‰é€»è¾‘)
        # KDJ
        kdj_df = df.ta.stoch(close='æ”¶ç›˜', k=9, d=3, smooth_k=3, append=True)
        if kdj_df is not None and not kdj_df.empty:
            kdj_signal = self._extract_kdj_signal(kdj_df.reset_index(drop=True), code)
            if kdj_signal:
                ta_signals.setdefault('KDJ', []).append(kdj_signal)

        # CCI
        cci_df = df.ta.cci(close='æ”¶ç›˜', length=14, append=True)
        if cci_df is not None and not cci_df.empty:
            cci_signal = self._extract_cci_signal(cci_df.iloc[-1].item(), code)
            if cci_signal:
                ta_signals.setdefault('CCI', []).append(cci_signal)
                
        # RSI
        rsi_df = df.ta.rsi(close='æ”¶ç›˜', length=14, append=True)
        if rsi_df is not None and not rsi_df.empty:
            rsi_signal = self._extract_rsi_signal(rsi_df.iloc[-1].item(), code)
            if rsi_signal:
                ta_signals.setdefault('RSI', []).append(rsi_signal)

        # BOLL
        boll_df = df.ta.bbands(close='æ”¶ç›˜', length=20, std=2, append=True)
        if boll_df is not None and not boll_df.empty:
            boll_signal = self._extract_boll_signal(boll_df.reset_index(drop=True), code)
            if boll_signal:
                ta_signals.setdefault('BOLL', []).append(boll_signal)
        
        
        return ta_signals
    

    def _extract_macd_signal(self, df: pd.DataFrame, diff_col: str, macd_col: str, prefix: str) -> Dict[str, Any]:
        """æå– MACD é‡‘å‰ä¿¡å· (åŸæœ‰é€»è¾‘)"""
        # ... (æ­¤å¤„æ˜¯æ‚¨åŸæœ‰çš„ MACD ä¿¡å·æå–é€»è¾‘ï¼Œä¸ºä¿æŒä¸€è‡´æ€§çœç•¥å®ç°ç»†èŠ‚ï¼Œä½†åŠŸèƒ½è¢«ä¿ç•™) ...
        # ç¡®ä¿ MACD DIF å’Œ MACD åˆ—åæ­£ç¡®
        signal_col = f'{prefix}_Signal'
        
        if diff_col in df.columns and macd_col in df.columns and len(df) >= 2:
            df = df.tail(2).reset_index(drop=True)
            
            dif_0 = df[diff_col].iloc[-1]
            dea_0 = df[macd_col].iloc[-1]
            dif_1 = df[diff_col].iloc[-2]
            dea_1 = df[macd_col].iloc[-2]
            
            signal = ''
            if (dif_1 < dea_1) and (dif_0 >= dea_0): # é‡‘å‰å‘ç”Ÿ
                if dif_0 >= 0:
                    signal = 'é›¶è½´ä¸Šé‡‘å‰'
                else:
                    signal = 'é›¶è½´ä¸‹é‡‘å‰'
            
            if signal:
                return {'è‚¡ç¥¨ä»£ç ': df['è‚¡ç¥¨ä»£ç '].iloc[-1], signal_col: signal}
        return {}


    def _extract_kdj_signal(self, df: pd.DataFrame, code: str) -> Dict[str, Any]:
        """æå– KDJ ä¿¡å· (åŸæœ‰é€»è¾‘)"""
        # ... (æ­¤å¤„æ˜¯æ‚¨åŸæœ‰çš„ KDJ ä¿¡å·æå–é€»è¾‘ï¼Œä¸ºä¿æŒä¸€è‡´æ€§çœç•¥å®ç°ç»†èŠ‚ï¼Œä½†åŠŸèƒ½è¢«ä¿ç•™) ...
        # ç®€åŒ–çš„ KDJ é‡‘å‰/è¶…å–ä¿¡å·åˆ¤æ–­
        signal = ''
        if len(df) >= 2:
            k_0 = df['STOCHK_9_3_3'].iloc[-1]
            d_0 = df['STOCHD_9_3_3'].iloc[-1]
            j_0 = 3 * k_0 - 2 * d_0
            k_1 = df['STOCHK_9_3_3'].iloc[-2]
            d_1 = df['STOCHD_9_3_3'].iloc[-2]
            
            if (k_1 < d_1) and (k_0 >= d_0) and k_0 < 30: # è¶…å–åŒºé‡‘å‰
                signal = f'åº•èƒŒç¦»é‡‘å‰ (K={k_0:.1f}, J={j_0:.1f})'
            elif (j_0 < 30) and (j_0 > df['STOCHJ_9_3_3'].iloc[-2]) and (df['STOCHJ_9_3_3'].iloc[-2] < 20):
                 signal = f'æå€¼Jçº¿åè½¬ (K={k_0:.1f}, J={j_0:.1f})'
            elif (k_1 < d_1) and (k_0 >= d_0): # è¶‹åŠ¿ç¡®è®¤é‡‘å‰
                 signal = f'è¶‹åŠ¿ç¡®è®¤é‡‘å‰ (K={k_0:.1f}, J={j_0:.1f})'
            
            if signal:
                return {'è‚¡ç¥¨ä»£ç ': code, 'KDJ_Signal': signal}
        return {}


    def _extract_cci_signal(self, cci_val: float, code: str) -> Dict[str, Any]:
        """æå– CCI ä¿¡å· (åŸæœ‰é€»è¾‘)"""
        # ... (æ­¤å¤„æ˜¯æ‚¨åŸæœ‰çš„ CCI ä¿¡å·æå–é€»è¾‘ï¼Œä¸ºä¿æŒä¸€è‡´æ€§çœç•¥å®ç°ç»†èŠ‚ï¼Œä½†åŠŸèƒ½è¢«ä¿ç•™) ...
        # ç®€åŒ–çš„ CCI ä¸“ä¸šçŠ¶æ€åˆ¤æ–­
        signal = ''
        if cci_val < -200:
            signal = f'æåº¦è¶…å– ({cci_val:.2f})'
        elif cci_val < -100:
            signal = f'è¶…å–åŒº ({cci_val:.2f})'
        elif cci_val > 200:
            signal = f'æåº¦è¶…ä¹° ({cci_val:.2f})'
        elif cci_val > 100:
            signal = f'è¶…ä¹°åŒº ({cci_val:.2f})'
        else:
            signal = f'éœ‡è¡åŒº ({cci_val:.2f})'
            
        return {'è‚¡ç¥¨ä»£ç ': code, 'CCI_Signal': signal}


    def _extract_rsi_signal(self, rsi_val: float, code: str) -> Dict[str, Any]:
        """æå– RSI ä¿¡å· (åŸæœ‰é€»è¾‘)"""
        # ... (æ­¤å¤„æ˜¯æ‚¨åŸæœ‰çš„ RSI ä¿¡å·æå–é€»è¾‘ï¼Œä¸ºä¿æŒä¸€è‡´æ€§çœç•¥å®ç°ç»†èŠ‚ï¼Œä½†åŠŸèƒ½è¢«ä¿ç•™) ...
        # ç®€åŒ–çš„ RSI è¶…å–ä¿¡å·åˆ¤æ–­
        signal = ''
        if rsi_val < 30:
            signal = 'è¶…å–ä½ä½'
            
        if signal:
            return {'è‚¡ç¥¨ä»£ç ': code, 'RSI_Signal': signal}
        return {}


    def _extract_boll_signal(self, df: pd.DataFrame, code: str) -> Dict[str, Any]:
        """æå– BOLL ä¿¡å· (åŸæœ‰é€»è¾‘)"""
        # ... (æ­¤å¤„æ˜¯æ‚¨åŸæœ‰çš„ BOLL ä¿¡å·æå–é€»è¾‘ï¼Œä¸ºä¿æŒä¸€è‡´æ€§çœç•¥å®ç°ç»†èŠ‚ï¼Œä½†åŠŸèƒ½è¢«ä¿ç•™) ...
        # ç®€åŒ–çš„ BOLL ä½æ³¢/ç¼©å£ä¿¡å·åˆ¤æ–­
        signal = ''
        if len(df) >= 2:
            # å‡è®¾ BOLL çš„ä¸Šä¸‹è½¨åˆ—åä¸º 'BBL_20_2.0' å’Œ 'BBU_20_2.0'
            try:
                # æ£€æŸ¥å¸ƒæ—é€šé“å®½åº¦æ˜¯å¦å¾ˆçª„ï¼ˆä½æ³¢åŠ¨ï¼‰
                band_width = df['BBU_20_2.0'].iloc[-1] - df['BBL_20_2.0'].iloc[-1]
                band_width_prev = df['BBU_20_2.0'].iloc[-2] - df['BBL_20_2.0'].iloc[-2]
                
                # ä½æ³¢åŠ¨/ç¼©å£åˆ¤æ–­: å®½åº¦ä½äºæŸä¸ªé˜ˆå€¼ï¼Œå¹¶ä¸”æ­£åœ¨ç¼©å£
                if band_width / df['BBM_20_2.0'].iloc[-1] < 0.05 and band_width < band_width_prev:
                    signal = 'ä½æ³¢/ç¼©å£'
            except KeyError:
                return {} # åˆ—åä¸å­˜åœ¨åˆ™è¿”å›ç©º
                
            if signal:
                return {'è‚¡ç¥¨ä»£ç ': code, 'BOLL_Signal': signal}
        return {}


    def _get_ta_signals_parallel(self) -> Dict[str, pd.DataFrame]:
        """å¹¶è¡Œè·å–å†å²æ•°æ®å¹¶è®¡ç®—æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡ä¿¡å·"""
        
        ta_signals: Dict[str, List[Dict]] = {
            'MACD_12269': [],
            'MACD_6135': [],
            'KDJ': [],
            'CCI': [],
            'RSI': [],
            'BOLL': [],
            'MACD_12269_DYN': [], # <-- NEW: MACD åŠ¨èƒ½çŠ¶æ€
            'MACD_6135_DYN': [], # <-- NEW: MACD åŠ¨èƒ½çŠ¶æ€
            'MACD_12269_VAL': [], # <-- NEW: MACD å½“å‰ DIF å€¼
            'MACD_6135_VAL': [], # <-- NEW: MACD å½“å‰ DIF å€¼
        }

        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œè·å– {len(self.all_stock_codes)} ä¸ªè‚¡ç¥¨å†å²æ•°æ®å¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) as executor:
            future_to_code = {executor.submit(self._fetch_and_calculate_ta_signals, code): code 
                              for code in self.all_stock_codes}
            
            total_tasks = len(future_to_code)
            completed_tasks = 0

            for future in as_completed(future_to_code):
                code = future_to_code[future]
                completed_tasks += 1
                
                try:
                    signals = future.result()
                    for key, val_list in signals.items():
                        # åˆå¹¶ç»“æœåˆ°ä¸»å­—å…¸ä¸­
                        ta_signals[key].extend(val_list)
                    
                    if completed_tasks % 100 == 0 or completed_tasks == total_tasks:
                        print(f"    - è¿›åº¦: {completed_tasks}/{total_tasks} ({completed_tasks / total_tasks * 100:.1f}%) å®Œæˆ.")

                except Exception as exc:
                    print(f"    - âŒ {code} ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡ä¿¡å·æ—¶å‘ç”Ÿå¼‚å¸¸: {exc}")
        
        # å°†åˆ—è¡¨å­—å…¸è½¬æ¢ä¸º DataFrame å­—å…¸
        ta_dfs = {}
        for key, value in ta_signals.items():
            if value:
                ta_dfs[key] = pd.DataFrame(value)
                # ç¡®ä¿ä»£ç åˆ—æ˜¯çº¯æ•°å­—ï¼Œç”¨äºåç»­åˆå¹¶
                if 'è‚¡ç¥¨ä»£ç ' in ta_dfs[key].columns:
                    ta_dfs[key]['è‚¡ç¥¨ä»£ç '] = ta_dfs[key]['è‚¡ç¥¨ä»£ç '].astype(str).str.replace('sh', '').str.replace('sz', '').str.replace('bj', '').str.zfill(6)
        
        return ta_dfs


    def _consolidate_data(self, raw_data: Dict[str, pd.DataFrame], ta_signals: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """æ•´åˆæ‰€æœ‰æ•°æ®åˆ°æœ€ç»ˆæŠ¥å‘Šä¸­"""
        
        print("\nğŸ”„ å¼€å§‹æ•´åˆæ‰€æœ‰æ•°æ®...")
        
        # 1. æ”¶é›†æ‰€æœ‰è‚¡ç¥¨ä»£ç  (ä»¥æœ€å…¨çš„åˆ—è¡¨ä¸ºåŸºç¡€)
        all_codes = set()
        
        data_sources = [
            raw_data.get('spot_raw', pd.DataFrame()),
            raw_data.get('main_report_raw', pd.DataFrame()),
            raw_data.get('xstp_raw', pd.DataFrame()),
            raw_data.get('market_fund_flow_raw', pd.DataFrame()),
            raw_data.get('market_fund_flow_raw_10', pd.DataFrame()),
            raw_data.get('market_fund_flow_raw_20', pd.DataFrame()),
            raw_data.get('strong_stocks_raw', pd.DataFrame()),
            raw_data.get('consecutive_rise_raw', pd.DataFrame()),
            raw_data.get('ljqs_raw', pd.DataFrame()),
            raw_data.get('cxfl_raw', pd.DataFrame()),
            ta_signals.get('MACD_12269', pd.DataFrame()),
            ta_signals.get('MACD_12269_DYN', pd.DataFrame()), # <-- NEW
            ta_signals.get('MACD_12269_VAL', pd.DataFrame()), # <-- NEW
            ta_signals.get('MACD_6135', pd.DataFrame()),
            ta_signals.get('MACD_6135_DYN', pd.DataFrame()), # <-- NEW
            ta_signals.get('MACD_6135_VAL', pd.DataFrame()), # <-- NEW
            ta_signals.get('KDJ', pd.DataFrame()),
            ta_signals.get('CCI', pd.DataFrame()),
            ta_signals.get('RSI', pd.DataFrame()),
            ta_signals.get('BOLL', pd.DataFrame()),
        ]

        # ä»æ‰€æœ‰æ•°æ®æºä¸­æå–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        for df in data_sources:
            if not df.empty and 'è‚¡ç¥¨ä»£ç ' in df.columns:
                all_codes.update(df['è‚¡ç¥¨ä»£ç '].astype(str).str.replace('sh', '').str.replace('sz', '').str.replace('bj', '').str.zfill(6).tolist())

        # è½¬æ¢ä¸º DataFrame ä½œä¸ºåˆå¹¶åŸºç¡€
        final_df = pd.DataFrame({'è‚¡ç¥¨ä»£ç ': sorted(list(all_codes))})
        
        # 2. åˆå¹¶åŸºç¡€ä¿¡æ¯ (åç§°ã€é“¾æ¥)
        final_df['è‚¡ç¥¨ç®€ç§°'] = final_df['è‚¡ç¥¨ä»£ç '].map(self.all_stock_names)
        final_df['è‚¡ç¥¨é“¾æ¥'] = final_df['è‚¡ç¥¨ä»£ç '].apply(lambda x: self.stock_link_base + format_stock_code(x))

        # 3. åˆå¹¶å„ä¸ªæ•°æ®æº
        
        # 3.1 å®æ—¶è¡Œæƒ… (æœ€æ–°ä»·)
        spot_df = raw_data.get('spot_raw', pd.DataFrame())
        if not spot_df.empty:
            spot_df = spot_df[['è‚¡ç¥¨ä»£ç ', 'æœ€æ–°ä»·']].copy()
            final_df = final_df.merge(spot_df, on='è‚¡ç¥¨ä»£ç ', how='left')


        # 3.2 MACD/KDJ/CCI/RSI/BOLL (TA ä¿¡å·)
        ta_dfs_to_merge = []

        # MACD 12269 ä¿¡å·
        macd_12269_df = ta_signals.get('MACD_12269', pd.DataFrame())
        if not macd_12269_df.empty:
            ta_dfs_to_merge.append(macd_12269_df[['è‚¡ç¥¨ä»£ç ', 'MACD_12269_Signal']].rename(
                columns={'MACD_12269_Signal': 'MACD_12269'}))

        # **æ–°å¢** MACD 12269 åŠ¨èƒ½çŠ¶æ€å’Œæ–œç‡
        macd_12269_dyn_df = ta_signals.get('MACD_12269_DYN', pd.DataFrame())
        if not macd_12269_dyn_df.empty:
            ta_dfs_to_merge.append(macd_12269_dyn_df[['è‚¡ç¥¨ä»£ç ', 'MACD_12269_DYN', 'MACD_12269_SLOPE']])

        # **æ–°å¢** MACD 12269 å½“å‰ DIF å€¼
        macd_12269_val_df = ta_signals.get('MACD_12269_VAL', pd.DataFrame())
        if not macd_12269_val_df.empty:
            ta_dfs_to_merge.append(macd_12269_val_df[['è‚¡ç¥¨ä»£ç ', 'MACD_12269_DIF']])


        # MACD 6135 ä¿¡å·
        macd_6135_df = ta_signals.get('MACD_6135', pd.DataFrame())
        if not macd_6135_df.empty:
            ta_dfs_to_merge.append(macd_6135_df[['è‚¡ç¥¨ä»£ç ', 'MACD_6135_Signal']].rename(
                columns={'MACD_6135_Signal': 'MACD_6135'}))
            
        # **æ–°å¢** MACD 6135 åŠ¨èƒ½çŠ¶æ€å’Œæ–œç‡
        macd_6135_dyn_df = ta_signals.get('MACD_6135_DYN', pd.DataFrame())
        if not macd_6135_dyn_df.empty:
            ta_dfs_to_merge.append(macd_6135_dyn_df[['è‚¡ç¥¨ä»£ç ', 'MACD_6135_DYN', 'MACD_6135_SLOPE']])
            
        # **æ–°å¢** MACD 6135 å½“å‰ DIF å€¼
        macd_6135_val_df = ta_signals.get('MACD_6135_VAL', pd.DataFrame())
        if not macd_6135_val_df.empty:
            ta_dfs_to_merge.append(macd_6135_val_df[['è‚¡ç¥¨ä»£ç ', 'MACD_6135_DIF']])

        # KDJ ä¿¡å·
        kdj_df = ta_signals.get('KDJ', pd.DataFrame())
        if not kdj_df.empty:
            ta_dfs_to_merge.append(kdj_df)

        # CCI ä¿¡å·
        cci_df = ta_signals.get('CCI', pd.DataFrame())
        if not cci_df.empty:
            ta_dfs_to_merge.append(cci_df)

        # RSI ä¿¡å·
        rsi_df = ta_signals.get('RSI', pd.DataFrame())
        if not rsi_df.empty:
            ta_dfs_to_merge.append(rsi_df)

        # BOLL ä¿¡å·
        boll_df = ta_signals.get('BOLL', pd.DataFrame())
        if not boll_df.empty:
            ta_dfs_to_merge.append(boll_df)
        
        # åˆå¹¶æ‰€æœ‰ TA ä¿¡å·
        for ta_df in ta_dfs_to_merge:
            final_df = final_df.merge(ta_df, on='è‚¡ç¥¨ä»£ç ', how='left')


        # 3.3 å…¶ä»–ç­›é€‰å› å­ (ç®€åŒ–ä¸ºæ˜¯å¦å­˜åœ¨/æ¬¡æ•°)
        
        # å¼ºåŠ¿è‚¡æ± 
        strong_df = raw_data.get('strong_stocks_raw', pd.DataFrame())
        final_df['å¼ºåŠ¿è‚¡'] = final_df['è‚¡ç¥¨ä»£ç '].isin(strong_df['è‚¡ç¥¨ä»£ç ']).map({True: 'æ˜¯', False: 'å¦'})

        # é‡ä»·é½å‡
        ljqs_df = raw_data.get('ljqs_raw', pd.DataFrame())
        final_df['é‡ä»·é½å‡'] = final_df['è‚¡ç¥¨ä»£ç '].isin(ljqs_df['è‚¡ç¥¨ä»£ç ']).map({True: 'æ˜¯', False: 'å¦'})

        # è¿ç»­ä¸Šæ¶¨
        consecutive_rise_df = raw_data.get('consecutive_rise_raw', pd.DataFrame())
        if not consecutive_rise_df.empty:
            consecutive_rise_df['è¿æ¶¨å¤©æ•°'] = pd.to_numeric(consecutive_rise_df['è¿æ¶¨å¤©æ•°'], errors='coerce')
            consecutive_rise_df = consecutive_rise_df.sort_values(by='è¿æ¶¨å¤©æ•°', ascending=False)
            consecutive_rise_df = consecutive_rise_df.drop_duplicates(subset=['è‚¡ç¥¨ä»£ç '], keep='first')
            final_df = final_df.merge(consecutive_rise_df[['è‚¡ç¥¨ä»£ç ', 'è¿æ¶¨å¤©æ•°']], on='è‚¡ç¥¨ä»£ç ', how='left')
        final_df['è¿æ¶¨å¤©æ•°'] = final_df['è¿æ¶¨å¤©æ•°'].fillna(0).astype(int)

        # æŒç»­æ”¾é‡
        cxfl_df = raw_data.get('cxfl_raw', pd.DataFrame())
        if not cxfl_df.empty:
            cxfl_df['æ”¾é‡å¤©æ•°'] = pd.to_numeric(cxfl_df['æ”¾é‡å¤©æ•°'], errors='coerce')
            cxfl_df = cxfl_df.sort_values(by='æ”¾é‡å¤©æ•°', ascending=False)
            cxfl_df = cxfl_df.drop_duplicates(subset=['è‚¡ç¥¨ä»£ç '], keep='first')
            final_df = final_df.merge(cxfl_df[['è‚¡ç¥¨ä»£ç ', 'æ”¾é‡å¤©æ•°']], on='è‚¡ç¥¨ä»£ç ', how='left')
        final_df['æ”¾é‡å¤©æ•°'] = final_df['æ”¾é‡å¤©æ•°'].fillna(0).astype(int)
        
        # ç ”æŠ¥ä¹°å…¥æ¬¡æ•°
        main_report_df = raw_data.get('main_report_raw', pd.DataFrame())
        if not main_report_df.empty:
            main_report_df['ç ”æŠ¥ä¹°å…¥æ¬¡æ•°'] = main_report_df['æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-ä¹°å…¥'] + main_report_df['æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-å¢æŒ']
            final_df = final_df.merge(main_report_df[['è‚¡ç¥¨ä»£ç ', 'ç ”æŠ¥ä¹°å…¥æ¬¡æ•°']], on='è‚¡ç¥¨ä»£ç ', how='left')
        final_df['ç ”æŠ¥ä¹°å…¥æ¬¡æ•°'] = final_df['ç ”æŠ¥ä¹°å…¥æ¬¡æ•°'].fillna(0).astype(int)

        # å‡çº¿å¤šå¤´æ’åˆ— (å®Œå…¨å¤šå¤´æ’åˆ—)
        xstp_df = raw_data.get('xstp_raw', pd.DataFrame())
        xstp_df['å®Œå…¨å¤šå¤´æ’åˆ—'] = xstp_df['å¤šå¤´æ’åˆ—å¤©æ•°'].apply(lambda x: 'æ˜¯' if x >= 10 else 'å¦')
        final_df = final_df.merge(xstp_df[['è‚¡ç¥¨ä»£ç ', 'å®Œå…¨å¤šå¤´æ’åˆ—']], on='è‚¡ç¥¨ä»£ç ', how='left')
        final_df['å®Œå…¨å¤šå¤´æ’åˆ—'] = final_df['å®Œå…¨å¤šå¤´æ’åˆ—'].fillna('å¦')
        
        # èµ„é‡‘æµå‘
        fund_flow_cols = ['èµ„é‡‘æµå…¥å‡€é¢']
        
        # 5æ—¥èµ„é‡‘
        fund_5d = raw_data.get('market_fund_flow_raw', pd.DataFrame())
        if not fund_5d.empty:
            fund_5d = fund_5d[['è‚¡ç¥¨ä»£ç '] + fund_flow_cols].rename(columns={'èµ„é‡‘æµå…¥å‡€é¢': '5æ—¥èµ„é‡‘æµå…¥'})
            final_df = final_df.merge(fund_5d, on='è‚¡ç¥¨ä»£ç ', how='left')

        # 10æ—¥èµ„é‡‘
        fund_10d = raw_data.get('market_fund_flow_raw_10', pd.DataFrame())
        if not fund_10d.empty:
            fund_10d = fund_10d[['è‚¡ç¥¨ä»£ç '] + fund_flow_cols].rename(columns={'èµ„é‡‘æµå…¥å‡€é¢': '10æ—¥èµ„é‡‘æµå…¥'})
            final_df = final_df.merge(fund_10d, on='è‚¡ç¥¨ä»£ç ', how='left')
            
        # 20æ—¥èµ„é‡‘
        fund_20d = raw_data.get('market_fund_flow_raw_20', pd.DataFrame())
        if not fund_20d.empty:
            fund_20d = fund_20d[['è‚¡ç¥¨ä»£ç '] + fund_flow_cols].rename(columns={'èµ„é‡‘æµå…¥å‡€é¢': '20æ—¥èµ„é‡‘æµå…¥'})
            final_df = final_df.merge(fund_20d, on='è‚¡ç¥¨ä»£ç ', how='left')


        # 4. å¡«å……ç©ºå€¼
        
        # å¡«å……å­—ç¬¦å‹ç©ºå€¼
        final_df['æœ€æ–°ä»·'] = final_df['æœ€æ–°ä»·'].fillna(0) # ä»·æ ¼å¡«å…… 0
        
        # å¯¹æ–°çš„ TA ä¿¡å·åˆ—å¡«å……ç©ºå€¼
        for col in [
            'MACD_12269', 'MACD_6135',
            'MACD_12269_DYN', 'MACD_12269_SLOPE', 'MACD_12269_DIF', # <-- æ–°å¢çš„ 3 åˆ—
            'MACD_6135_DYN', 'MACD_6135_SLOPE', 'MACD_6135_DIF', # <-- æ–°å¢çš„ 3 åˆ—
            'KDJ_Signal', 'CCI_Signal', 'RSI_Signal', 'BOLL_Signal'
        ]:
            if col in final_df.columns:
                if 'SLOPE' in col or 'DIF' in col:
                    # æ–œç‡å’Œ DIF å€¼æ˜¯æ•°å€¼ï¼Œä¿æŒ NaN
                    pass
                elif 'DYN' in col:
                    final_df[col] = final_df[col].fillna('---')
                else:
                    final_df[col] = final_df[col].fillna('')
            else:
                if 'SLOPE' in col or 'DIF' in col:
                    final_df[col] = np.nan # æ•°å€¼å‹ç©ºåˆ—
                elif 'DYN' in col:
                    final_df[col] = '---' # å­—ç¬¦å‹ç©ºåˆ—
                else:
                    final_df[col] = ''
        
        # 5. æœ€ç»ˆåˆ—é¡ºåºè°ƒæ•´
        final_columns = [
            'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ç®€ç§°', 'æœ€æ–°ä»·', 
            'å¼ºåŠ¿è‚¡', 'é‡ä»·é½å‡', 'è¿æ¶¨å¤©æ•°', 'æ”¾é‡å¤©æ•°',
            
            # MACD æ–°å¢å› å­
            'MACD_12269', 'MACD_12269_DIF', 'MACD_12269_DYN', 'MACD_12269_SLOPE',
            'MACD_6135', 'MACD_6135_DIF', 'MACD_6135_DYN', 'MACD_6135_SLOPE',
            
            # å…¶ä»– TA
            'KDJ_Signal', 'CCI_Signal', 'RSI_Signal', 'BOLL_Signal',
            
            # å…¶ä»–åŸºç¡€å› å­
            'ç ”æŠ¥ä¹°å…¥æ¬¡æ•°', 'å®Œå…¨å¤šå¤´æ’åˆ—', 
            '5æ—¥èµ„é‡‘æµå…¥', '10æ—¥èµ„é‡‘æµå…¥', '20æ—¥èµ„é‡‘æµå…¥', 
            'è‚¡ç¥¨é“¾æ¥'
        ]
        
        # ç¡®ä¿åªé€‰æ‹©å­˜åœ¨çš„åˆ—
        final_df = final_df[[col for col in final_columns if col in final_df.columns]]
        
        print("âœ… æ•°æ®æ•´åˆå®Œæˆã€‚")
        return final_df


    def _save_to_excel(self, processed_data: Dict[str, pd.DataFrame], final_df: pd.DataFrame):
        """å°†æ‰€æœ‰ç»“æœä¿å­˜åˆ° Excel æ–‡ä»¶ï¼ŒåŒ…å«å¤šå¼  Sheet"""
        
        file_name = f"è‚¡ç¥¨ç­›é€‰æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d')}.xlsx"
        full_path = os.path.join(self.config.SAVE_DIRECTORY, file_name)
        
        print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜æŠ¥å‘Šåˆ°: {full_path}...")
        
        with pd.ExcelWriter(full_path, engine='xlsxwriter') as writer:
            
            # 1. ä¿å­˜æ±‡æ€»è¡¨ (ç¬¬ä¸€ä¸ª Sheet)
            final_df.to_excel(writer, sheet_name='æ•°æ®æ±‡æ€»', index=False)
            
            # 2. ä¿å­˜åŸå§‹/å¤„ç†åçš„æ•°æ®è¡¨ (ä½œä¸ºç­›é€‰ä¾æ®)
            
            # ç®€åŒ–åçš„æ•°æ®å­—å…¸ï¼Œä»…åŒ…å«éœ€è¦è¾“å‡ºåˆ° Excel çš„å…³é”®è¡¨
            output_sheets = {
                'ä¸»åŠ›ç ”æŠ¥ç­›é€‰': processed_data['processed_main_report'],
                'å‡çº¿å¤šå¤´æ’åˆ—': processed_data['processed_xstp_df'],  # ä½¿ç”¨å¤„ç†åä¸”è¿‡æ»¤åçš„æ•°æ®
                'å®æ—¶è¡Œæƒ…': processed_data['spot_df'],  # ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®
                '5æ—¥å¸‚åœºèµ„é‡‘æµå‘': processed_data['market_fund_flow_raw'],
                '10æ—¥å¸‚åœºèµ„é‡‘æµå‘': processed_data['market_fund_flow_raw_10'],
                '20æ—¥å¸‚åœºèµ„é‡‘æµå‘': processed_data['market_fund_flow_raw_20'],
                'å¼ºåŠ¿è‚¡æ± ': processed_data['strong_stocks_raw'],
                'è¿ç»­ä¸Šæ¶¨': processed_data['consecutive_rise_raw'],
                'é‡ä»·é½å‡': processed_data['ljqs_raw'],
                'æŒç»­æ”¾é‡': processed_data['cxfl_raw'],
                'MACD_12269é‡‘å‰': ta_signals.get('MACD_12269', pd.DataFrame()),  # å¢åŠ æ ‡å‡†å‘¨æœŸè¡¨æ ¼
                'MACD_6135é‡‘å‰': ta_signals.get('MACD_6135', pd.DataFrame()),  # å¢åŠ åŠ é€Ÿå‘¨æœŸè¡¨æ ¼
                'KDJè¶…å–é‡‘å‰': ta_signals.get('KDJ', pd.DataFrame()),
                'CCIä¸“ä¸šçŠ¶æ€': ta_signals.get('CCI', pd.DataFrame()),  # **æ”¹è¿›ç‚¹ï¼šä½¿ç”¨ä¸“ä¸šçŠ¶æ€**
                'RSIè¶…å–': ta_signals.get('RSI', pd.DataFrame()),
                'BOLLä½æ³¢': ta_signals.get('BOLL', pd.DataFrame()),
                'å‰åæ¿å—æˆåˆ†è‚¡': processed_data['top10_board_stocks_raw']
            }
            
            for sheet_name, df in output_sheets.items():
                if not df.empty:
                    # å°è¯•ç»Ÿä¸€è‚¡ç¥¨ä»£ç æ ¼å¼
                    if 'è‚¡ç¥¨ä»£ç ' in df.columns:
                        df['è‚¡ç¥¨ä»£ç '] = df['è‚¡ç¥¨ä»£ç '].apply(lambda x: str(x).zfill(6))
                        
                    df.to_excel(writer, sheet_name=sheet_name, index=False)

        print("âœ… æŠ¥å‘Šä¿å­˜æˆåŠŸ!")


    def run(self):
        """è¿è¡Œåˆ†ææµç¨‹"""
        try:
            # 1. è·å–æ‰€æœ‰åŸå§‹æ•°æ®
            raw_data = self._get_all_raw_data()
            
            # 2. é¢„å¤„ç†æ•°æ® (ä»…å¤„ç†éœ€è¦è¿‡æ»¤çš„ä»£ç å’Œåç§°æ˜ å°„)
            processed_data = {}
            processed_data.update(raw_data)
            
            # 3. å¹¶è¡Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡ä¿¡å·
            ta_signals = self._get_ta_signals_parallel()

            # 4. æ•´åˆæ•°æ®åˆ°æœ€ç»ˆæŠ¥å‘Š
            final_df = self._consolidate_data(raw_data, ta_signals)

            # 5. ä¿å­˜æŠ¥å‘Š
            self._save_to_excel(processed_data, final_df)

        except Exception as e:
            print(f"è‡´å‘½é”™è¯¯: ç¨‹åºè¿è¡Œå¤±è´¥: {e}")


# ==============================================================================
# ç¨‹åºå…¥å£
# ==============================================================================
if __name__ == '__main__':
    # ç¤ºä¾‹è¿è¡Œæ—¥æœŸ (å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´)
    # é»˜è®¤è·å–è¿‘ä¸€å¹´çš„æ•°æ®
    analyzer = StockAnalyzer()
    analyzer.run()
